# CVE Data Service
It provides 3 Api's which fetch fresh data from local mongo db. Tha Data are inserted to local through 2 jobs
* One time full run job
* Incremental job

The data quality is maintained by
* De-Duplication job

### One time full run job
This job run only one time once the server is up. It migrates all the data from nvd database to local database. Once the job is completed it updated the status to **COMPLETED** in **batch_meta_data** collection.

### Incremental job
This job run every 10 minutes. It fetches the last modified from the **cve_data** collection and sync the data from nvd database. This job run only if the full time job is completed by checking the status **COMPLETED**

### De-Duplication job
This job run every 20 minutes. It fetches the data from **cve_data** and take only the description and cve id and move it to **de_dup_data_hold** where description is maintained unique. So that any data which has dupicate description will be removed from **cve_data**. Also Data without description will be deleted to ensure quality.

### API's
This Application has 3 secured endpoints which fetch data filtered by id, score and last no. of days.

The Api are secured with basic authentication with single user.

```
username: user
paswword: user-password
```
### API Documentation
Swagger is used to document the api and swagger api also secured with above username and password
### Data base
Mongo DB is used to maintain data. There are three collections used
* cve_data - stores the cve data
* batch_meta_data - stores the meta data of one time job whether it is COMPLETED, RUNNING or YET_TO_START
* de_dup_data_hold - stores the description, id and last modified date of cve id with description as id.